\documentclass{sig-alternate}
\usepackage[utf8]{inputenc} 
%\usepackage[hidelinks]{hyperref}
%\usepackage[autostyle,french=guillemets,babel]{csquotes}
\usepackage{graphicx} % support the \includegraphics command and options
%\usepackage[backend=biber]{biblatex}
%\addbibresource{biblio.bib}
% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{booktabs}
\usepackage{array}
\usepackage{paralist}
\usepackage{verbatim} 
\usepackage{amsfonts}
\usepackage{fancyhdr}
\usepackage{times}
\usepackage{url}
%\pagestyle{fancy} % options: empty , plain , fancy
%\renewcommand{\headrulewidth}{0pt} % customise the layout...
%\lhead{}\chead{}\rhead{}
%\lfoot{}\cfoot{\thepage}\rfoot{}

\title{From Nested Virtualization Architecture \\To 2D Security Management for Distributed Clouds}

\author{
\numberofauthors{3}
\alignauthor
Alex Palesandro\\
\affaddr{Orange Labs, France}\\
\texttt{alex.palesandro@gmail.com}
\alignauthor
Aurélien Wailly\\
\affaddr{Orange Labs, France}\\
\texttt{aurelien.wailly@orange.com}
\alignauthor
Marc Lacoste\\
\affaddr{Orange Labs, France}
\texttt{marc.lacoste@orange.com}
}

\begin{document}
\maketitle

\abstract{
%Today, hypervisors have to find a complex trade-off between functionalities provided and security assurance. Those requirements are contrasting by design:
%adding new features will generally increases the LoC and consequently the attack surface. On the contrary, those code additions are required to properly fulfill market requests. 
%
%Nested virtualization is a technique capable to diversify hypervisor features. Exploiting an extra layer of virtualization, we will be able to decouple different requirements, avoiding the need to find delicate trade-off.
%
%In this paper, we will analyze the state of nested virtualization in modern hypervisor and evaulating the impact of utilization of microhypervisor to enforce a stronger security level.
%The problem of homogeneity over multiple IaaS providers is receiving considerable attention with the evolution toward nested virtualization. These new architectures unveil user-centric opportunities such as efficient resources management and VM migration. However the inherent drawbacks hinder its global adoption with a larger TCB and the complexity to monitor another virtualization layer. Thus, we argue that the promising architectural view of micro hypervisors approach is the key to the separation of hypervisor duties and reducing the attack surface.
%
%Furthermore, our architecture mushrooms commodity and micro hypervisors to leverage nested virtualization in terms of user-data privacy, modularity, TCB size and compatibility. These design principles are evaluated for each architecture configuration and compared to establish a reference security architecture. The resulting combination is built over common hypervisors empowered with micro hypervisors features. A reference implementation proven the architecture to be viable and will be extended to meet broader hypervisor scopes, enabling migration over heterogeneous cloud servers.
Distributed cloud computing is now moving user-centric. The pro-mise of this evolution is: (1) unified resource management across IaaS providers, e.g., live migration independent from hypervisor technology; (2) increased customizability to choose the hypervisor services needed to realize fully à la carte, self-service clouds. However, a reality check shows that major interoperability and security barriers must be lifted, and complex trade-offs be found between functionalities provided and security assurance.
Nested virtualization (NV) brings both a homogeneous interface for distributed hypervisor features and enhanced IaaS security, protecting VMs even in case of hypervisor compromise. However, practical NV adoption is still hindered by code additions to an already very large hypervisor TCB and by limited hardware support. New distributed IaaS architectures are therefore required.\\

In this paper, we argue that micro-hypervisor (MH) architectures are the key to overcome such NV limitations. 
From the previous challenges, we derive a set of design principles that a distributed IaaS architecture should satisfy. 
We compare possible architectural designs combining NV with micro-hypervisor features to find the best trade-off between user data privacy, modularity, TCB size, and compatibility with multiple platforms. 
We sketch how the resulting architecture may serve as a basis for 2D security management of a cloud of clouds: vertically, across layers for hardened IaaS security, and horizontally spanning cloud domains for end-to-end security.
}

%The first challenge means that threats will be both vertical, spanning layers, and horizontal, spanning domains  the SUPERCLOUD being a multi-layer, multi-domain distributed cloud infrastructure. Vertically, attacks currently target several infrastructure layers (e.g., VMs, hypervisor). Unfortunately, most existing defenses are generally for single layers only. This makes it difficult to grasp the overall extent of an attack. Horizontally, threats may propagate through the network from cloud to cloud. Unfortunately, most existing defenses are for single clouds only. Lack of interoperability in security policies and mechanisms is thus a major barrier to  unified hybrid cloud security. The second challenge means that although many defense mechanisms may be leveraged in this 2D landscape, they remain difficult to configure and to reconcile. The current “by hand” approach becomes a nightmare for security administrators. Despite some automated solutions for managing security of single clouds, there is currently no solution truly applicable to federations of clouds in practice.



%The resulting combination is built over common hypervisors empowered with micro hypervisors features. 
%
%rchitecture mushrooms commodity and micro hypervisors to leverage nested virtualization
%
%
%
%Furthermore, our architecture mushrooms commodity and micro hypervisors to leverage nested virtualization in terms of user-data privacy, modularity, TCB size and compatibility. These design principles are evaluated for each architecture configuration and compared to establish a reference security architecture. 
%
%enhance NV architecture next generation of distributed clouds security and interoperabiltiyi issues.
%
%
%failureverall, current NV architectures lack some of the dedicated features found in modern hypervisors and the impossibility to rely on a tiny TCB (violating principles DP3 and DP4).
%If the first one is currently being addressed by hypervisor developers, the second simply has not be achieved with modern hypervisors so far.
%
%ypervisors have to find a complex trade-off between functionalities provided and security assurance. Those requirements are contrasting by design:
%%adding new features will generally increases the LoC and consequently the attack surface. On the contrary, those code additions are required to properly fulfill market requests. 
%
%the inherent drawbacks hinder its global adoption with a larger TCB and the complexity to monitor another virtualization layer.
%
%First, independence from the provider resulting in lower infrastructure operation overheads, more rapid deployment of services, but also increased homogeneity the customer being free a particular hypervisor technology. Second, increased customizability, as the customer can choose which virtualized services (e.g., for security) may be deployed resulting in fully a la carte clouds. Third, new business opportunities, as SCs and their (virtual) apps might become new markets in the manner of ecosystems from the mobile computing world (e.g., iPhone, Android). 
%
%User-centric: de DCC
%vers plus d'homogeneity
%problemes 
%verticaux
%horizontaux.
%
%NV: solutions pour résoudre certains de ces problèmes.
%
%VErticaux: ...
%Horizontaux: ...
%
%Mais limites ... + ...
%New architectural solutions must be found.
%
%In this paper explore potential of micro-hypervisor architectures to enhance NV architecture next generation of distributed clouds security and interoperabiltiyi issues.
%
%We explore design principles properties.
%
%We compare architecutral solutions combining NV+MH to find the best trade off between ..., ???; ... meilleure approche.
%
%We sketch finally: how this type of architecture could enable to perform 2D supervision xl alyer x domain.


\section{Introduction}
\label{sec:intro}

%% Motivation
%Cloud computing platform are a solid reality nowadays. 
\noindent Distributed cloud computing is now becoming a reality. Modern cloud platforms are able to provide elastic use of resources, optimizing their allocation to meet user needs. However, currently deployed distributed cloud infrastructures present several limitations.

% Interop
DCC does not handle heterogeneous infrastructures which secludes providers in non-evolving hardware.
% Securite
Also, security remains the last hurdle toward wide adoption of DCC. The user data are no more self contained but distributed among all parties without any proof of confidentiality, integrity or availability.

%% Specific problem considered
We classified problems related to DCC horizontally and vertically. The horizontal view gathers features related to interactions between IaaS stacks, such as live migrations. The vertical view addresses features close to the isolation of execution environment on the same physical machine. This classification provide a global coverage of problems to solve to deliver a secure, stable and robust architecture.

%% "In this paper we show that"
As a first element of answer, the nested virtualization~\cite{turtle:ibm} performed a breakthrough with enhanced isolation capabilities on the same physical machine. The hypervisor is now virtualized by a thin layer~\cite{cloudvisor:zhang} to counter failures. Furthermore, the horizontal challenges were also included in this tiny layer to deliver an homogeneous interface for commodity hypervisors~\cite{art:blan, xclo:blank}. However these classic approaches suffers from several shortcomings detailed in Section~\ref{ref:challenges}. Thus we propose a novel architectural approach to undertake remaining problems.

%% Differences with others
The previous works created both horizontal and vertical basic blocks from scratch. While being a necessary step, these approaches does not inherits the advances performed in terms of operating system security. The software architecture are mainly monolithic and yet-another-layer fends off security problems without
figuring them out. Our approach learns from security issues fixed by OS architecure~\cite{liedtke1995micCon} and apply these patterns to leverage nested virtualization. In this paper we show that component-based architecures are a promising design for the next generation of clouds.

This paper is organized as follows. Section~\ref{ref:challenges} details the constraints of nested virtualization for the two dimension of our solution. In Section~\ref{sec:rw} we analyze the nested virtualization ecosystem and position existing solutions regarding our design principles. In Section~\ref{sec:classic}, we details limitations of classical nested virtualization approach and in Section~\ref{sec:mh} we present the microvisor approach. In Section~\ref{sec:archcomp} we compare cloud architectures propositions, combining nested virtualization and microvisors, leveraging the design principles grid introduced before.
%Furthermore, in Section 6 we define a security architecture for multi-cloud scenario, with an analysis of necessary software components to satisfy vertical design principles.
In Section~\ref{sec:conclu}, we conclude the paper with future works and our vision of the SuperCloud.
% in section in section 6 we define a security architecture for multi-cloud scenario, with an analysis of necessary software components to satisfy vertical design principles. In section 8, we conclude the paper with future works in section 8.

\section{Challenges and Design Principles}
\label{ref:challenges}

First, deploying cloud applications able to transparently leverage resources of several heterogeneous platforms is still difficult. The concept of super-cloud~\cite{art:blan, xclo:blank} tries notably to overcome such issues. Multi-platform coordination is hard, primarily due to lock-in to different standards such as VM formats. Unfortunately, such lock-in is not only due to market strategic decisions, but also reflects heterogeneity of virtualization technologies. For example, each cloud provider may use different storage systems or different formats to store VMs images. Different hypervisors have nowadays a low degree of compatibility between them. This generally prevents leveraging some popular features like VM live migration between different platforms. Incompatibility is even greater if we consider that each platform may adopt several types of virtualization techniques. This situation induces a tight dependency between the customer and the cloud provider. It may prevent guaranteeing service availability by relying on alternative providers, or to set up geographical optimizations due to cost or origin of traffic. This has resulted in some dramatic data server failures in recent years, causing prolonged outage of service for many applications. In what follows, we refer to this class of multi-platform issues as \textit{horizontal} challenges.

Second, a number of issues have been raised about user data privacy and platform integrity. From the user perspective, users would like to preserve privacy of their data stored on the cloud platform. However, due to overprivileged hypervisors, a curious or malicious administrator could easily retrieve such data~\cite{cloudvisor:zhang}. In a multi-tenant cloud platform, physical resource sharing between users may lead not only to data leakage or but also attacks against the IaaS~\cite{bot:att, sec:you}.
From the provider perspective, a key objective is to thus guarantee platform integrity against rogue VMs. However, commodity general-purpose hypervisors (GPHs) make it difficult to observe deeply all layers of a running IaaS platform. Indeed, running GPHs at the highest level of privilege hampers detection and reaction on the hypervisor itself in presence of faulty or malicious behavior -- unless to cause interruption of service for all hosted VMs. Thus, both user-centric and provider-centric visions of the cloud have a problem with overprivileged hypervisors.
%: the platform administrator cannot perform in-depth infrastructure monitoring nor can users concretely inspect administrator actions on their data. 
A major challenge for new generations of cloud infrastructures is thus to find acceptable trade-offs between such conflicting requirements. In what follows, we refer to this class of layer-oriented issues as \textit{vertical} challenges.

We identified five key design principles (DP) that a IaaS architecture should implement to meet the previous challenges. In what follows, those principles will serve as reading template to analyze different architectures.
\begin{itemize}[]
\item \textbf{DP1 User Data Privacy} A curious or malicious administrator (or another platform user) should not be authorized to inspect and analyze user data and VM instances without explicit user consent relying on mutually trusted services. A trade-off should be found to allow providers to detect and react to potential threats, but also to prevent unlimited platform and user data access in such inappropriate operator behaviors. Thus, a platform administrator should not manage the infrastructure directly using the highest level of privilege. Instead, his actions on user data objects should be validated by a mutually-trusted kernel run in the most privileged mode. This kernel should also enforce memory page encryption to prevent snooping when pages are swapped out.
\item \textbf{DP2 Fail-Safe Modular Architecture} The architecture should be fail-safe: for instance, to enable automatically migration of instances or user-data in presence of a threat and to recover from software failures. To reach this goal, the amount of safety-critical components should be as low as possible to mimize the attack surface. Similarly, the overall design should be as modular as possible to enable platform reconfiguration.
\item \textbf{DP3 Small TCB} The number of potential failures and bugs in the platform is directly linked with the code size executed at the highest level of privilege. Thus, an architecture with a tiny TCB (Trusted Computing Base) will improve safety and integrity by design.
\item \textbf{DP4 Inter-Platform Support} The cloud architecture should allow supporting directly different platforms and service providers. The same user virtual instances should be allowed to be run (and potentially migrated) unmodified over different IaaS platforms.
\item \textbf{DP5 Compatibility with Legacy} Evolution in the IaaS architecture should avoiding disrupting existing third party applications. Thus, platform interfaces should be kept as close as possible to existing ones, to prevent code rewriting notably for applications.
\end{itemize}
In addition to the above functional design principles that specify which features have to be achieved by the platform architecture, another set of non-design principles (NDP) should be considered regarding effective feasibility of implementing the architecture. We just give an example in terms of platform usability:
\begin{itemize}[]
\item \textbf{NDP1 Minimal Additional Code} A major issue could be represented by the amount of code to be added and maintained to an existing architecture to meet functional requirements. Despite not being a strictly a technical limitation of the architecture, it could become a show-stopper to its practical use.
\end{itemize}
In our analysis, we will consider not only the overall suitability of the architecture, but also the amount of effort needed to develop and deploy it. Table \ref{int:des} summarizes the previous principles and which class of requirements they address.
 
\begin{table}
\caption{Design Principles for a Distributed IaaS Platform.\label{int:des}}
\begin{tabular}{lll}
\toprule
\textbf{Id} & \textbf{Design Principle} & \textbf{Class of Requirement} \\
\midrule
DP1 & User Data Privacy & Vertical \\
DP2 & Fail-Safe Modular Architecture & Vertical \\ 
DP3 & Small TCB & Vertical \\
DP4 & Inter-Platform Support & Horizontal \\
DP5 & Compatibility with Legacy & Horizontal \\
NDP1 & Minimal Additional Code & -- \\
\bottomrule
\end{tabular}
\end{table}
 
\section{Related Work}
\label{sec:rw}

% Intro + performance issues
\noindent A growing body of research has investigated building architectures and infrastructures integrating a subset of those design principles leveraging nested virtualization (NV)~\cite{turtle:ibm,art:blan, cloudvisor:zhang, Inception, hvx:usenix}. The distributed cloud feature set may be expanded using two levels of virtualization instead of a single one. This design allows to specialize hypervisor functions per layer, each layer addressing a subset of features, simplifying overall development compared to a general-purpose hypervisor. However, NV development on x86 architecture was initially hindered by severe performance issues~\cite{rec:virt}.
% Perfomance issuess adressed
However, several works have shown it possible to realize low-overhead NV using dedicated implementation architecture~\cite{turtle:ibm}, or to recover performance loss exploiting multi-level consolidation~\cite{art:blan}. NV slowdown can now be considered an acceptable price to achieve advanced features -- hardware manufacturers are also developing new hardware primitives to reduce this overhead~\cite{vmcs:nakajima}.

However, so far no architecture has currently addresses both vertical and horizontal set of challenges simultaneously. XenBlanket~\cite{art:blan} does not investigate cloud architectural security concerns (DP2, DP3), limiting its focus to providing new features on a coordinated multi-provider cloud. Cloudvisor~\cite{cloudvisor:zhang} proposed a NV-based security architecture, but cannot run more than one nested hypervisor at time, which is a criticial requirement for multi-provider cloud platform (DP4). In the super-cloud vision~\cite{xclo:blank}, each user runs its own L1 hypervisor instance to realize  a blanket layer overcoming incompatibilities between different providers. However, security issues have not been addressed.

Other approaches based on a single layer of virtualization do not fulfill all principles either. Self-Service Clouds (SSC)~\cite{ssc:art} introduces a complete security architecture to overcome major security and privacy issues of currently deployed cloud infrastructures. The aim is to reconcile user-centric and provider-centric requirements of the cloud. Despite being similar to the super-cloud approach (DP4), SSCs introduces new components that have to be directly managed by the user. This change of interface with user VMs prevents moving straightforwardly to the new platform without having to change its  applications (DP5).

% Integration NDSS Taming
To reduce the TCB size, DeHype~\cite{wu2013TamHosHypMosDepExe} presented a dissected version of KVM, moving a great part of the code to user space. DeHype satisfies all vertical design principles, re-interpreting the microkernel approach in a KVM setting. It increases a lot the robustness and security of a cloud platform leveraging KVM (DP1), but does not address horizontal challenges for a multi-provider service.

\section{Current Nested Virtualization}
\label{sec:classic}

\subsection{Principle}

\noindent \textit{Nested virtualization (NV)} refers to a system architecture with two layers of virtualization~\cite{turtle:ibm}. It consists in ``virtualized'' virtualization: the guest system virtualizes a nested guest. The concept may be generalized to an arbitrary number of nested guest layers, leading to recursive virtualization~\cite{rec:virt,Popek:1974:FRV:361011.361073}. (Full) virtualization is able to execute tasks in a deprivileged context that normally requires a privileged execution. With NV, this approach may be extended to virtualization itself: a guest hypervisor may be run with nested guest VMs without requiring any change to any of them.
%More formally, Popek \& Golberg \cite{Popek:1974:FRV:361011.361073} discussed this subject, introducing the concept of ``recursively virtualizable'' machine and giving an initial definition of recursive virtual machines: If it is possible for a virtual machine to run under itself a copy of the VMM that could also exhibit all the properties of the VMM and this procedure could be repeated until the resources of the systems are consumed, then the original machine is recursively virtualizable.

Two layers should be distinguished when migrating to an NV architecture: (1) the hypervisor running above the hardware (\textit{L0 hypervisor}); and (2) the nested hypervisor (\textit{L1 hypervisor}). Nested guests are generally referred to as \textit{L2 guests}.
Unfortunately, virtualization comes with a price due to the extra layer of indirection introduced: the computational overhead is generally acceptable when dealing with single-layer virtualization, but grows exponentially when adding further levels~\cite{rec:virt}. This huge performance overhead prevented NV adoption during many years. However, Ben Yehuda et al. finally proposed an architecture tending towards more reasonable overheads~\cite{turtle:ibm}.

NV feasibility opened plenty of new possibilities and avenues for research that have been largely discussed in the literature~\cite{turtle:ibm,rec:virt,art:blan}. Such works all tend to diversify hypervisor functionalities, introducing new features but also keeping existing ones. It turns out that each layer addresses clearly different sets of issues.

L0 tackles vertical aspects of the platform. It aims to guarantee the best performance and strongest level of isolation possible. L0 represents the last line of defense of the platform and a privileged point for monitoring of its global status.

L1 is responsible for horizontal feature set. It has to provide the widest possible support for different platforms and the ability to virtualize using different techniques e.g., para-virtualization, hardware-assisted virtualization, dynamic binary translation. {\sffamily To address such requirements, Williams et al.~\cite{art:blan} proposed a patched version of Xen, Xen Blanket, to realize an L1 virtualization layer designed to run over different hypervisors. This notably enables to run and to perform live migration of the same VM over different physical cloud infrastructures.} % A migrer dans le related work?

\subsection{Limitations}

\noindent Today, NV presents several limitations related to hardware support {\sffamily and software state of implementation}. 

First, to support NV, the hypervisor has to provide an exact copy of hardware virtualization primitives. Full virtualization with hardware assistance (HAV) is the most popular technique, but requires quite a complex dedicated support.
HAV primitives assist instruction emulation, memory address translation, and management of devices. Both Xen and KVM propose {\sffamily nested VMX/SVN features} that allow to efficiently handle nested hardware virtualization on single-layer hardware primitives.
Full virtualization is currently the only virtualization technique supported for L1 virtualization due to its ability to run unmodified guest OSes -- and thus hypervisors. Paravirtualization (PV) would on the contrary require an ad hoc modified hypervisor to act as L1 (thus violating the NDP1 principle).
%To address this performance problems, several hardware producers proposed new facilities, like Intel VMCS shadowing, that reduces the amount of nested VMEXIT when handling a nested guest VMEXIT.
Despite still poor NV performance and not being yet stable on modern hypervisors~\cite{xen:test}, such feature is under heavy development and will hopefully be in a usable state soon.

Second, due to current monolithic GPH architectures, each feature directly introduced within the hypervisor such as security enhancements enlarges the TCB~\cite{cloudvisor:zhang}. Therefore, a huge amount of code runs in highly privileged mode and must be trusted. Several works discuss and analyze the overall TCB of modern GPHs, always bigger than 100 KLoC~\cite{nova, xmhf}. This approach directly violates the DP3 design principle.
%that identified a small TCB as a major requirement for a solid architecture.
%A brief comparison of TCB of widespread GPH is depicted in figure \ref{fig:tcbchart}. 
%More importanly, this is particularly true looking at the monolithic approach of commercial hyper-visors, where any addition to the hypervisor body enlarges the TCB.
Moreover, the previous architecture does not improve overall stability of the infrastructure. The bottom-most hypervisor L0 faces the same issues as single-layer GPH architectures: a large TCB implies also that a failure experienced in one of its critical components may trigger a generalized failure of the whole platform (violating the DP2 principle). Besides, in standard GPH architectures, the administrator has the entire control of the platform and could potentially snoop and inspect user VM status and data (violating the DP1 principle).
Such designs notably do not take advantage of the possibility {\sffamily to use a platform compatibility layer}, and more modular architectures with only a tiny security-critical kernel.

Overall, current NV architectures lack some of the dedicated features found in modern hypervisors and the impossibility to rely on a tiny TCB (violating principles DP3 and DP4).
If the first one is currently being addressed by hypervisor developers, the second simply has not be achieved with modern hypervisors so far.

\section{Micro-Hypervisors}
\label{sec:mh}

%\begin{figure}
%\caption{GPH TCB comparison \cite{nova}}
%\label{fig:tcbchart} 
%\begin{center}
%\includegraphics[width=\columnwidth]{figures/TCBchart.png}
%\end{center}
%\end{figure}

% Xen and KVM TCB

\subsection{Principle}

\noindent To solve the TCB size issue, the idea of \textit{micro-hypervisor (MH)} architecture was introduced~\cite{nova, NoHype, xmhf, mccune2010TruEffTCBRedAtt}. Such hypervisor design draws inspiration from evolution in OS architecture (e.g., extensible, micro-, exo-, component-based kernels). Within the hypervisor are distinguished security-critical modules from non-sensitive code. The aim is to expel as much code as possible from the TCB make the hypervisor ultra-thin. Some hypervisor components (e.g., device drivers, VM address space management) may be virtualized outside the MH, isolated, and restarted in case of compromise~\cite{nova}. The utmost MH removes the virtualization layer altogether~\cite{NoHype}.


%MH = MK+ H.
MH architectures may be seen as convergence of traditional hypervisor and micro-kernels (MK).
%1) MK
%Perspective: minimalisme: 
%with a traditional microkernel-like design that tries to consistently reduce the amount of code running with the highest privilege level.
From the MK design principles legacy, the MH is guided by TCB minimization. 
%-- Définition du mk
%A micro-kernel traditionally consists in a minimal kernel running in privileged mode, offering only a few fundamental services to other modules (e.g, scheduling, IPC, memory management) running in a less privileged domain. All other components, such as device drivers, are moved out in user-space.
%-- Définition du mh:
%Therefore, leveraging this concept of microkernels, a micro hypervisor (MH) is composed from a small kernel providing only essential functions, like scheduling, IPC, memory management and VMX extension. 
Thus, it features a minimal kernel running in privileged mode, offering only a few fundamental services (e.g, scheduling, IPCs, memory management, VMX extensions) to other modules running in less privileged domains. All other components, such as device drivers, are moved out in user-space. 
% Skip inconvénients du MK
%1) Inconvénients du mk: performance.
%Microkernels had been questioned because of the wasteful performance of first generations, due to IPC intrinsic cost. This argument had been completed confuted by Liedtke in 1993: \cite{liedtke1993ImpIPCbyKerDes,liedtke1995micCon}.
%While the benefits of such a design has been questioned due to the cost of IPCs in first generations of micro-kernels, such arguments have since then been completely dispelled~\cite{liedtke1993ImpIPCbyKerDes,liedtke1995micConnova}.
%-- Bénéfices du mk
The main benefit of such increased modularity is
% a) Bénéfices du mk: flexibility in privilege
% One of the benefits of micro-kernels is to enable to easily redesign a hierarchy of privileges. 
%
%The different groups may hold correspond to different trust relationships of principals running Control is finer than in the hypervisor, both by the granularity of isolation (lightweight threads), and by a unique control point of RT behavior in the scheduler. Device drivers are run in , allowing great flexibility for device sharing patterns.
to easily define groups of user-space services, each group sharing a common a set of privileges. Trust relationships between groups may be arbitrarily defined, mirroring those between sets of principals or applications sharing the system. 
%For instance, a user application normally trusts the micro-kernel and only the set of user-space services it requires. However, such drivers and libraries may not be trusted by every application run on the system. User applications share the system but may need to support completely different set of system services. 
% -- Les personalités:
% In addition, MH inherits the concept of micro-kernel to implement different ``personalities''. 
This allows MK to implement different ``personalities'': device drivers being run in user mode, such fine-grained control allows great flexibility to implement device sharing patterns.
%
%2) H
%
%Plus facile dans un contexte d'hyperviseurs:
%However, the interest of such ``personalities'' has been largely reduced by the fact that system services, device drivers and even applications have to be completely re-designed to fit this new architectural pattern. 
%
%Therefore, with the introduction of VMs, microkernels lost the battle in favor of hypervisors, in terms of popularity.
While the interest of realizing such ``personalities'' in traditional MKs somewhat lessened as system services, drivers, and even applications had to be completely re-designed (hypervisors offering better primitives for abstraction with the notion of VM), 
%
%
%3) MH.
%
such flexibility still remains a major benefit of coupling micro-kernel design with virtualization~\cite{OKL4}.

%1) Pas de tiny TCB
%However, the great advantage of tiny TCB, provided by microkernel, was not provided also by hypervisors. 
%2) Architecture monilithic
%As we analyzed before, they present normally a monolithic architecture, like the great part of modern OS. 
%This feature kept alive the interest in microkernels, in particular trying to couple microkernel benefits with virtualization

%-- Exemples: Several micro-hypervisor have been proposed in literature \cite{xmhf, nova}. 
%
%=> -- MH = MK+ virtualization. They rely on the micro-kernel paradigm, extending it to virtualization. MV

%-- Relation entre MH et principes: 
%* MH naturally satisfy vertical design principles (DP1,DP3, DP4). 
MHs are particularly well adapted to sastisfy vertical design principles.
% Security:
%Pourquoi: 
For instance, MH design increases reliability as services crashing in user space may be restarted without bringing down the entire system (DP2).
%Fail-safe principle:
%Moving Finally, this extraction process drives to a more solid platform, considering that user-space crashes are generally not fatal for the entire system integrity. 
The attack surface is also lowered by the small TCB size, the minimal kernel only containing security-critical components and forming a last line of defense (DP3).
%The tiny core could be considered the only system-critical componente of the architecture and, due to its relative small dimension and the consequent minor attitude to vulnerabilities,it could represent the ``last line of defense''.
MH might also address some horizontal principles. 
%Interop principle:
%Qu'est ce que c'est:
``Personalities'' are concretely a set of processes handling specific functions running in user-space. Implementing such features outside the kernel makes it easier for each user to rely on different instances of such personalities running concurrently, possibly in a distributed manner (DP4).
%This process separation between users could enforce a straightforward mechanism to neutralize VM-to-VM attack from a malicious user. Moreover, user-space processes are easier to debug with commodity tools (GDB, valgrind).



% Enlever les exemples qui ne sont pas significatifs.
% A possible example, that will be analyzed in next section, is the user-space VMM component of Nova, Vancouver, that resides in user-space \cite{nova}.
% In addition, this approach is not far from the one proposed in DeHype \cite{wu2013TamHosHypMosDepExe}, where a consistent part of the KVM hypervisor has been demoted in user-space.

% Texte additionnel sur les MH:
%Architectural solutions were also created to make the hypervisor more minimal and flexible, targetting its two most vulnerable elements: (1) the core hypervisor itself; and (2) the management VM (e.g., Xen Dom0).
%
%A first class of solutions aims \textit{to reduce the hypervisor size}. The new hypervisor architecture should be more minimal, drawing inspiration from evolution in OS architecture (e.g., extensible, micro-, exo-, component-based kernels). Within the hypervisor are distinghuished security-critical modules from non-sensitive code. The aim is to expel as much code as possible from the TCB and target ultra-thin hypervisors, also known as \textit{micro-hypervisors}. For instance, some components of the hypervisor (e.g., device drivers, VM address space management) may be virtualized outside the micro-hypervisor, isolated, and restarted in case of compromise~\cite{NOVA}. The extreme case is to remove the virtualization layer altogether~\cite{NoHype}.
%Unfortunately, although promising, such architectures usually require extensive code rewriting. They also provide a very limited number of resource management services unlike an operational IaaS infrastructure. They are thus hard to apply to mainstream hypervisors today.

% Texte sur les MK, H, et MV
%Embedded virtualization brings benefits to achieve several such properties, for instance abstraction and isolation by multiplexing and isolating VMs. However, current hypervisor architectures show strong limitations for many others. A main flaw is the huge TCB size, leading to reliability, security, and administration issues. Flexibility is rather poor, as for device sharing. RT guarantees are also difficult due to two-level system scheduling, i.e., threads at VM-level, and VMs at hypervisor-level. Finally, resource control remains coarse-grained through heavyweight VMs. 
%
%\textit{Micro-kernel} design has thus been increasingly popular to meet such challenges. Reducing the kernel to its fundamental elements, and making the rest of the OS deprivileged outside results in an extremely minimal TCB that may be formally verified. Strong isolation and high-perfromance communication between address spaces is also achieved through very efficient IPCs. Micro-kernels increasingly support virtualization: privileged instructions are intercepted and emulated in a dedicated system service. Control is finer than in the hypervisor, both by the granularity of isolation (lightweight threads), and by a unique control point of RT behavior in the scheduler. Device drivers are run in user space above the micro-kernel, allowing great flexibility for device sharing patterns. 
%
%Such architectures are very similar, although the hypervisor is driven by abstraction, to match closely virtual to real resources, while micro-kernels are guided by TCB minimization.
%They tend to converge: the \textit{micro-visor} allows to run both VMs and threads over a lightweight execution environment~\cite{OKL4}. Like micro-kernels, it has a minimal TCB, and high-performance asynchronous IPCs between VMs, applications, or user-mode drivers. Like hypervisors, it allows virtualization of CPU, memory, or I/O through a hardware abstraction layer (HAL). Arbitrary control over resource partitioning in security domains or RT scheduling of threads or VMs is also possible. Finally, the micro-visor offers great architectural flexibility: drivers may be virtualized in a VM, or executed as system services in their own address space. 

\subsection{Limitations}

\noindent The MH approach also showed several limitations. First, support for hardware is lacking, notably in terms of device drivers. Fortunately, this issue may be addressed leveraging I/O passthrough techniques, despite some resulting exclusive allocation challenges.
Second, several cloud issues are simply not addressable with GPHs. However, GPHs are now widely adopted and foundation of existing cloud platforms. While a GPH exports mature APIs to upper software layers and is also tightly integrated with cloud toolkits, MHs lack such API stability and integration, requiring explicit dedicated code to be written -- thus violating DP5.  
Third, for the sake of kernel size, MHs could lack several virtualization features commonly available on modern GPH hypervisors. For instance, XMHF does not support multiple guests. Such limitations applicable for MH architectures alone may be lifted partially or totally when applying MH design to NV architectures. 

\section{Architecture Comparison}
\label{sec:archcomp}

\begin{figure*}
\begin{center}
\includegraphics[width=2\columnwidth]{globalcut.png}
\end{center}
\caption{Different Types of Nested Architectures.}
\label{fig:io}
\end{figure*}

\noindent Adding an extra layer of virtualization enables to introduce a wide range of new features in the IaaS infrastructure, but does not reduce the TCB size. As already discussed, introducing MH design within a nested IaaS architecture could represent a new approach to improve NV benefits by overcoming such limitations. In what follows, we analyze the four possible architectures shown in Figure~\ref{fig:io} to achieve nesting of GPH and MH, highlighting their potential, and assessing their benefits and weaknesses w.r.t. to the design principles of Section~\ref{ref:challenges}, as well as their cost of implementation.

\subsection{GPH/GPH}

\noindent The first architecture only features GPHs in both layers to serve as point of comparison. This type of architecture enables several remarkable features related to VM management flexibility such as live migration over different platforms, and transparent migration of virtualized clusters across data centers, fulfilling principle DP4. More generally, assuming complete and correct support of virtualization primitives for nested hardware in mainstream hypervisors, this architecture satisfies all horizontal design principles. 

However, it fails to safisfy vertical design principles as TCB size is that of currently deployed NV architectures. The interest of other MH-based architectures will thus be to introduce isolation and privacy improvements by reducing the TCB, while still keeping horizontal features.

%Although this architectures presents an extra layer between the nested guest, normally controlled by the cloud user and the system critical part, L0, the latter is far from a satisfying security level. The TCB of KVM that is represented by the entire Linux Kernel is normally around 200 KLoCs, considering the medium size of a deployed Linux kernel.
%Moreover, default KVM configuration does not provide a transparent protection mechanism between different VMs, so that compromising one instance of QEMU, that is executed in user-space, an attacker could compromise all the others VMs on the platform.

\subsection{MH/MH}

\noindent This architecture is considered only to highlight improvements brought by a MH design compared to a GPH/GPH architecture. An MH/MH implementation would meet the vertical requirements missing in the previous approach. 
As in single-layer MH architectures, hypervisor disaggregation and minimization overcomes issues posed by monolithic system architectures and over-privileged administrative VMs (DP1). The smaller resulting TCB also improves resilience of the platform against a large set of software failures (DP2) and reduces the surface of attack of the most privileged part of the IaaS infrastructure (DP3). 

However, the interest this class of architecture remains limited as it cannot overcome any of the generally cited issues of single-layer MHs such as compatibility with legacy hypervisor architectures (DP5). While several horizontal properties are theoretically achievable, they would require a large development effort to implement the relevant features such as interoperable advanced resource management. Moreover, the lack of nested VMX support prevents testing in practice this type of architecture, as MH usually rely on VMX primitives to create nested HVM guests.

Overall, with this architecture, if vertical challenges are well addressed as in single-layer MHs, it does not provide any improvement for horizontal challenges, despite NV being used to bridge gaps between IaaS platform eco-systems.

\subsection{MH/GPH}
\label{par:mog}

\noindent The third architecture aims to alleviate security concerns. It combines a GPH as L0 and a MH as L1. 
%Several MH are proposed in literature focusing on different .
%Therefore, this model tries to exploit microhypervisor as L1 hypervisor in order to enforce better isolation between L2 and L0. L1 will exploit the emulated nested VMX provided by GPH L0 and virtualize L2. 
%With this approach, we try to isolate the attacker in a VM virtualized on a secured layer, in order to prevent attacks to L0. The attacker would have to face with an essential virtualization layer and it would not be able to attack the back-end virtualization layer. 
This approach is interesting as it may be easily deployed without requiring any extra code addition to the GPH. Hardware support is not a real barrier as existing GPH-based platforms could potentially export nested VMX features to guests. Even if this is not yet the case in modern cloud platforms, this lack may be considered temporary due to the experimental status of such features.

However, there is no TCB reduction as the code size running in L0 kernel space is as big as before. 
Besides, adopting a MH as L1 prevents using inter-platform enhanced features. As already seen for MH design, the price of having a thin hypervisor is normally paid with a lack of certain features. For example, XMHF only supports a single guest~\cite{xmhf}. Thus, this architectural approach cannot provide any new horizontal features leveraging NV. Therefore, this approach can only provide the same features as those deployed today, with an increased but not sufficient level of isolation.

\subsection{GPH/MH}
\label{par:gom}

\noindent This last approach achieves a smaller TCB than other architectures, due increased modularity brought by the micro-kernel-like design of the L0 layer -- satisfying DP3. Leveraging a GPH like Xen or KVM for the L1 layer provides the user with an environment looking identical to those used in production today -- satisfying DP5. The L1 GPH is normally integrated with modern cloud toolkits like OpenStack, and will thus support third-party applications -- satisfying DP4.
Therefore, this architecture achieves a stronger level of isolation due to vertical use of NV to introduce an additional hardware-protected security monitor. Thanks to the GPH, the MH layer remains transparent to the user and should not impact the functional properties of the IaaS platform.

This class of architecture may suffer from two types of limitations. First, nested VMX extensions must be exposed to the L1 hypervisor to let him ``nest'' another HVM guest. This requirement is implemented by GPHs like Xen and KVM, but usually not included in the key features to be provided by a MH: implementing nested VMX may be estimated to around 1KLoC, to be compared with the size of a typical MH (2-20 KLoC)~\cite{xmhf}.
More generally, the MH quest towards ever increasing minimalism could represent a serious limitation to preserving functions of existing platforms: the constraint of privileged code size may force MH developpers to drop some features considered as non-essential. This may apply to NV-related primitives, but also to other types of features. For instance, XMHF may only virtualize a single L1 instance at a time. While this may be acceptable if the platform objective to enforce strict resource access control in a single-provider private cloud, it hinders having a platform model enabling the user to run its own hypervisor as L1 to set up a self-service cloud independently from the underlying provider -- as in that case, multiple L1 hypervisors would need to run concurrently on the L0.

Second, device drivers should be correctly managed. Drivers are a major MH issue, due to costs of development or of adaptation to a new architecture. Such challenges may be addressed using device assignment: the L1 GPH hypervisor manage the physical device with the proper driver now running in a lower level of privilege. To be workable, this approach would require exclusive allocation to be simply implementable, e.g., using SR-IOV~\cite{sriov}.

\begin{table*}
\caption{Architecture Comparison.\label{fin:conf}}
\centering
\begin{tabular}{llcllll}
\toprule
Id & Functional Design Principle & Class of Requirement & GPH/GPH & MH/MH & MH/GPH & GPH/MH\\
\midrule
DP1  & User-Data Privacy               & Vertical   & $\times$      & $\checkmark$  & $\times$ & $\checkmark$ \\
DP2  & Fail-Safe modular architecture  & Vertical   & $\times$      & $\checkmark$  & $\times$ & $\checkmark$ \\
DP3  & Small TCB                       & Vertical   &  $\times$     & $\checkmark$  & $\times$ & $\checkmark$ \\
DP4  & Inter-Platform support          & Horizontal & $\checkmark$  & $\times$      & $\times$ & $\checkmark$ \\
DP5  & Compatibility with Legacy       & Horizontal & $\checkmark$  & $\times$      & $\times$ & $\checkmark$ \\
NDP1 & Minimal Additional Code         & --         & $\checkmark$  & $\times$      & $\times$ & $\checkmark$ \\
\bottomrule
\end{tabular}
\end{table*}
 
\subsection{Discussion}

\noindent Overall, how do the architectures above compare w.r.t. to the two main reported benefits of NV, i.e., vertical, through an increased level of isolation between hypervisor and customer VMs, and horizontal to easily achieve multiple provider platform interoperability at system level? Table~\ref{fin:conf} summarizes the previous analysis. 

The GPH/MH architecture appears as the most interesting to expand the NV promised benefits. Through a solid and secure MH as L0, it is the only one able to reduce the platform TCB. This would bring several benefits towards a more secure infrastructure. First, a guarantee that the platform administrator could not lose control of the system thanks to an extra security layer. Second, certification perspectives: Klein et al.~\cite{Klein:2009} showed that less than 10 KLoC kernels could be formally verified, under several conditions, which is far from be achievable today with standard GPH/GPH approach where the TCB is an order of 
magnitude bigger than MHs~\cite{nova}.

However, the effort to set up a GPH/MH is strongly dependent on the technique for L2 virtualization. As already seen, to support L2 guests with hardware-assisted virtualization which is becoming mainstream, the MH needs to export nVMX (nested VMX) primitives. On the other end, adopting paravirtualization or dynamic binary translation for L2 does not requires particular hardware support, and thus would not require MH patching to set up a running platform. However, PV remains limited by supporting only a subset of system features which could be an issue as a general solution.
%The last point of interest is related to device management. If MH act as L0 hypervisor, it has to deal with hardware devices, and this could necessitate of a significant code writing. In fact, there are several technologies, like Direct Assignment, allowing to bypass hypervisor control of a device. Those techniques are useful but they reduce the flexibility in the device management, requiring for example exclusive allocation of a device to a guest. To contrast this drawbacks, PCI-E propose the possibity to multiplex device with a set of virtual devices called virtual functions proposed to the L0 hypervisor, that will relax the contraint of exclusive allocation. Unfortunately this approach could not give the same flexibilty given by other techniques, like para-virtualization 
%With MH over GPH, MH could directly assigne devices to GPH that is able to implement  para-virtualize device, for example. 
%This will relief the MH of a part of devices management, giving to the GPH the responsibility to drive concretely the device but without losing interesting features. Therefore, we will need a limited amount of code to handle device without have to deal with each specific device.

Therefore, a MH-based architecture could increase the feature set of current NV architectures, mostly vertically. The main remaining barrier is to come up with an MH implementation supporting HAV nested guests. We are currently working on a GPH/MH implementation based on Xen over NOVA aiming to lift this limitation using PV.

\section{Towards 2D Security Management}
\label{ref:arch}

\indent We now sketch how the previous enhanced-NV design could enable to build a security architecture for a distributed cloud infrastructure  (DCI) satisfying both vertical and horizontal requirements. Such DCIs will face 2D threats, vertical spanning layers, and horizontal, spanning domains DCIs being multi-layer, multi-domain distributed cloud infrastructures. Vertically, attacks currently target several infrastructure layers (e.g., VMs, hypervisor). Unfortunately, most existing defenses are generally for single layers only. This makes it difficult to grasp the overall extent of an attack. Horizontally, threats may propagate through the network from cloud to cloud. Unfortunately, most existing defenses are for single clouds only. Lack of interoperability in security policies and mechanisms is thus a major barrier to  unified hybrid cloud security. DCI security thus requires 2D protection.

We consider the security architecture shown in Figure~\ref{fig:archisecu}. 

Supercloud
SUPERCLOUD Layer built SS cloud
Also security management both vertically and horizontally.

OS:

Provider MH: Assumption min V, XenDisagregated...
Above GPH: 
Achieve Vertical security Cross Layer security

GPH allows also to layer of interoperability horizontal blanket layer above the different MH to enalbe self-service security.

On the top are the VM built self-service security where security is personalized/customized.
Automation.
Cross-Layer Framewokr: VESPA
Cross-Domain Framework:
360 Atuomation


 This means: providing vertically a cross-layer integrated vision of security of the cloud and SUPERCLOUD infrastructure; defining horizontally a security abstraction layer to achieve a homogeneous level of security across clouds independently from underlying provider mechanisms; and integrating both dimensions smoothly. This approach is key to providing a unified view of security of the SUPERCLOUD.
Our ambition is to define a security supervision architecture and framework for the SUPERCLOUD enabling this 360 view of security management with a high level of automation. Thus, the SUPERCLOUD will bring unified, simple management of security for cloud of clouds. 

 Our vision is that the security of the SUPERCLOUD should be both self-managed and 360.

The second challenge means that although many defense mechanisms may be leveraged in this 2D landscape, they remain difficult to configure and to reconcile. The current “by hand” approach becomes a nightmare for security administrators. Despite some automated solutions for managing security of single clouds, there is currently no solution truly applicable to federations of clouds in practice.

two major security challenges: 

In terms of architecture:
The northbound, user-centric super-cloud API will implement self service security and dependability, allowing to build self-service clouds (SSC) where VM, network, and storage security may be personalized independently from the underlying provider. Such clouds may be defined at the service level to the full IaaS, relationships between SSC being flat or nested, also with complex trust relationships between sets of SSC according to the ecosystem relationships of the super-cloud providers providing the SSC. 
The southbound, provider-centric super-cloud API will define a unified security and dependenability management plane of the compute, data, and network resources independently from providers. This may apply for B2B use cases to management of clouds of clouds but also to device-to-cloud scenarios if devices are considered, with possible extensions to the personal cloud for device-to-device scenarios, the SSC taking the form of personal cloud-based digital infospheres where security and dependability may be totally user-controlled.
...
The SUPERCLOUD will fulfill that vision with a two-level infrastructure:
•	The lower part of the SUPERCLOUD is be a distributed infrastructure will realize the distribute resource abstraction layer federating distributed cloud resources and implementing the self-service security to build SSC. It will implement the northbound, user-centric super-cloud API.
•	Above, the upper part of the SUPERCLOUD will be a supervision infrastructure providing a set of security and resilience services to guarantee the security of the overall SUPERCLOUD architecture. It will realizing self-service security, end-to-end security, and resilience. It will implement the southbound, provider-centric super-cloud API.

and security management complexity. Th

\begin{figure}
\begin{center}
\includegraphics[width=10cm]{DCCArchitecture.png}
\end{center}
\caption{Security Architecture.}
\label{fig:archisecu}
\end{figure}

A DC 
%Our vision is that the security of the SUPERCLOUD should be both self-managed and 360°. Security will be autonomically managed through orchestration of a number of self-protection loops governing interactions between detection, decision, and reaction components. This approach enables simpler, stronger, and more efficient security management to detect and respond to threats [CPW03]. Security monitoring will also be 360°. This means: providing vertically a cross-layer integrated vision of security of the cloud and SUPERCLOUD infrastructure; defining horizontally a security abstraction layer to achieve a homogeneous level of security across clouds independently from underlying provider mechanisms; and integrating both dimensions smoothly. This approach is key to providing a unified view of security of the SUPERCLOUD.
%Our ambition is to define a security supervision architecture and framework for the SUPERCLOUD enabling this 360° view of security management with a high level of automation. Thus, the SUPERCLOUD will bring unified, simple management of security for cloud of clouds. 

Autonomous

Supercloud architecture

Proposition of Architecture

Base Layer

Supercloud layer

VESPA.

In the previous sections we proposed a functional analysis of cloud architecture in order to respect design principles that we identified in the introduction. In this section, we propose a GPH over MH implementation, based on .

\begin{itemize}[]
\item \textbf{Inter-platform support} Executed as L1, Xen would virtualize its nested guest initially using PV delivering the compatibility layer.
\item \textbf{Tiny TCB} The NOVA kernel will represent the only part of the platform executed at the highest level of privilege. Even the VMM, Vancouver, will be executed in the L0 user-space. The micro-kernel in L0 enforces a strictly modular approach to L0. Therefore, the VMM will present distinct processes instances for each L1 guest, enforcing a context division.
\item \textbf{3rd part compatibility} From a user point of view the architecture still exports the same interfaces provided by the Xen hypervisor, allowing the user to keep its applications unchanged.
\item \textbf{Fail-safe components architecture} Moreover, the tiny core is the only safety-critical software component. The system could potentially be able to recover any crash in different user-space components.
\end{itemize}

%The SUPERCLOUD project aims to define the architecture and build the infrastructure to fulfill the vision of user-centric secure and dependable management of a clouds of clouds. Our approach will be to define a new distributed architectural plane, the super-cloud providing an end-to-end interface both between user-centric and provider-centric views of multiple clouds. Its role will be both to provide a distributed resource abstraction and flexible but unified control for management of security and resilience.
%From the user perspective, the super-cloud will enable user-centric security and dependability through a unified distribution layer for cloud resources, independently from their type (computation, storage, and network) and from underlying cloud providers. It thus forms an intermediation layer for resources between their production by providers and their consumption by users. This in line with the vision introduced by IBM [X] as well as with the utility computing paradigm [X], but will go well beyond, leveraging this distribution layer to explore high customizability of user cloud security and dependability according to well-defined SLAs. 
%From the provider perspective, the super-cloud will also enable provider-independent control over security and resilience over the overall distributed cloud infrastructure, security being autonomous managed and guaranteed end-to-end. This will also make the resource distribution layer both secure and resilient. 
%The level of abstraction, from system to middleware interoperability of the super-cloud be also be tuned to allow trade-offs between user-centric and provider-centric control for security services. 
%In terms of architecture:
%The northbound, user-centric super-cloud API will implement self service security and dependability, allowing to build self-service clouds (SSC) where VM, network, and storage security may be personalized independently from the underlying provider. Such clouds may be defined at the service level to the full IaaS, relationships between SSC being flat or nested, also with complex trust relationships between sets of SSC according to the ecosystem relationships of the super-cloud providers providing the SSC. 
%The southbound, provider-centric super-cloud API will define a unified security and dependenability management plane of the compute, data, and network resources independently from providers. This may apply for B2B use cases to management of clouds of clouds but also to device-to-cloud scenarios if devices are considered, with possible extensions to the personal cloud for device-to-device scenarios, the SSC taking the form of personal cloud-based digital infospheres where security and dependability may be totally user-controlled.
%...
%The SUPERCLOUD will fulfill that vision with a two-level infrastructure:
%•	The lower part of the SUPERCLOUD is be a distributed infrastructure will realize the distribute resource abstraction layer federating distributed cloud resources and implementing the self-service security to build SSC. It will implement the northbound, user-centric super-cloud API.
%•	Above, the upper part of the SUPERCLOUD will be a supervision infrastructure providing a set of security and resilience services to guarantee the security of the overall SUPERCLOUD architecture. It will realizing self-service security, end-to-end security, and resilience. It will implement the southbound, provider-centric super-cloud API.
%In what follows, we describe the SUPECLOUD vision for each self-service security, self-managed security, end-to-end security and resilience properties. 
%
%For computing workloads, user-centric cloud security management faces two challenges.
%•	Lack of IaaS infrastructure openness: provider-controlled immutable hypervisors (or that mask access to the hardware) prevent users from taking advantage of hypervisor-level advanced resource management and security services such as high availability or VM introspection for fine-grained VM misbehavior detection and reaction. Such examples of vendor lock-in are already a notorious issue for single provider infrastructures [CSA Guidance]. They are a real barrier for hybrid clouds: the varying degree of openness of the underlying IaaS forces to achieve security interoperability in upper software layers instead of at system level as in multi-IaaS orchestration platforms, highly reducing user control over security management. Such limitations also prevent fine-grained trade-offs between provider and user control over security : among security services, users cannot choose between those to customize, and those to delegate to the provider infrastructure.
%•	Security threats for customer VMs: large, complex, overprivileged hypervisors are a serious risk for VMs [CSATT]. The assumption of a trusted hypervisor is no more, illustrated through many examples of VM escapes, breaking hypervisor isolation through exploitaiton of device drivers vulnerabilities [Virtunoid, CloudBurst]. A multi-layer approach to IaaS security is needed considering lower layers, to guarantee VM security even if the hypervisor layer is compromised. This challenge is intrisically linked with openness and flexibility issues: from a user perspective, to protect their VMs from an untrusted provider infrastructure, customers may wish adding their own security modules (or layer) in the infrastructure, provided it is open enough. Conversely, a provider may also wish to benefit from an open hypervisor architecture to harden its IaaS against rogue VM behaviors.
%Earlier IaaS architectures such as disaggregated hypervisors or nested virtualization provided partial answers to either of those issues but not both. Hypervisor disaggregation (for the Dom0 or the core hypervisor) achieves flexibility through the definition of clearly separated access control domains between provider-centric and user-centric security management planes where fine-grained trade-offs may be reached [SSC]. This approach is compatible with legacy hypervisors (Dom0 case) or requires new architectures (core hypervisor case). However, it only addresses security and flexibility challenges in a single cloud context, but not for interoperability of multiple independent hypervisors. Nested virtualization addresses the (vertical) security challenge by placing an additional hardware-protected security monitor beneath the untrusted virtualization layer [Turtles, CloudVisor] -- requiring a sufficiently open IaaS. It also features (horizontal) flexibility and interoperability benefits by defining a blanket layer on top of existing provider hypervisors in a hybrid cloud setting, enabler for self-service security for clouds of clouds [XenBlanket]. However, such horizontal and vertical benefits have not yet been combined in a unified security architecture. Moreover, the additional layer separation might also make user vs. provider trade-offs more coarse-grained than the previous approach.
%Hence, in SUPERCLOUD, we propose to define a new IaaS security architecture for distributed clouds that may combine the benefits of the two previous architectural approaches in terms of both layered design and modularity to achieve self-service cloud security with tuneable, fine-grained trade-offs with provider-centric security to protect customer VMs. The benefits of this hybrid approach will be to lift both barriers simultaneously, but also to be applicable in a large variety of underlying provider infrastructures. For instance, if the underlying hypervisor is not open, leveraging the benefits of nested virtualization for hypervisor interoperability; and otherwise, using either approach, depending on desired security vs. performance trade-offs, and compatibility with legacy systems or deployment of new security hardened IaaS architectures.
%
%



%
%%
%%%%Improving the Status Quo
%Udo Steinberg NOVA 6
%Virtualization layer is critical. Make it as small as possible.
%Design Principles:
%1)Fine-grained functional decomposition
% Microhypervisor (privileged)
% Multiple user-level VMMs (unprivileged)
% User-level drivers, applications (unprivileged)
%2)Principle of least privilege among all components
% Capability-based authorization model
%Ideas adopted from the microkernel world
%Those still existing limitations to nested HVM, made we focus on nested PV.
%Leveraging on the new architecture presented we propose a security architecture based on Xen and NOVA. 
%
%Xen is a well-known and wide-used hypervisor that is the base of several of most important cloud platforms.  We focus in particularly on the Xen support for para-virtualization. 
%
%Available from the first version of Xen in 2003, PV does not requires any specific hardware facilities. Even if some features drop in Amd64 architecture leaded to a little performance loss for PV compared to HVM guests, the real limit of PV is represented by the impossibility to virtualize Windows and other proprietary operating systems.
%However this technique is currently still exploited in widespread cloud platform like Amazon EC2.
%
%NOVA is a tiny micro-hypervisor able to virtualize several guests. It is a recent but promising open-source project developed at Technische Universitat Dresden. The aim of project is double: minimize the amount of code running in kernel mode and try boost virtualization.
%
%NOVA implements some interesting features, in particular from security point of view. It adopts a capability-based authorization model in order to implement the principle of least privilege among components. It supports SMP guests, VT-d Direct device assignement and NPT/EPT.
%
%The modular architecture of NOVA allows also to enforce a increased separation between different L1 guest. Leveraging the modular architecture of NOVA, each L1 guest communicates directly with a separate instance of the Virtual Machine Monitor, component of the hypervisor executed in user space. 
%
%The concept is to boot and use Xen as L1 hypervisor, inside a NOVA VMs. Xen hypervisor will be able to virtualize complete PV guests in a secured Cloud Platform. The presence of NOVA is completely transparent for the user.  

%Therefore, leveraging NOVA as L0 our platform could propose inter-platform features to the user. We have the opportunity to exploit a complete cloud toolkit with the Xen hypervisor implementing features like inter-platform migration and improved redundancy, as described in the Xen Blanket approach.

\section{Conclusion and Future Work}
\label{sec:conclu}

In previous sections we provided a global analysis of modern challenges of cloud computing  and how those could be globally addressed addressed leveraging nested virtualization and different hypervisor architectures. 

Future works will be focused on two complementary parts.
Firstly, they will concern the completion of the architecture of security in order to concretely meet horizontal design principles, identifying key components, similarly as done for the vertical properties.
At the same time, a major effort will be directed on enlarging the initial implementation.

%On the other hand, L1 choice is much simpler. Previous analysis identified Xen as the most suitable hypervisor for this role. The capacity to support different virtualization techniques added to the ability of running without HV support, makes Xen suitable to act as compatibility layer. 
%
%After this initial study, the first step will be deploying a minimal nested architecture testing ``out-of-the-box'' features and limitations. The following part will concern the conception of patch and extensions in order to adapt the general design of MH to properly act as L0.
%The final goal is to provide an architecture able to leverage nested virtualization cloud platforms improvements, having a smaller TCB and allowing customers to leverage flexible migrations and scheduling.


%\section{Conclusion}
%{\scriptsize
%\bibliographystyle{abbrv}
%\bibliography{biblio}
%}

{\scriptsize
\bibliographystyle{abbrv}
\bibliography{biblio}
}
\end{document}
